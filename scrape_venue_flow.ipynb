{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import os\n",
    "import json\n",
    "from functions import start_selenium, parse_date\n",
    "import html\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been having a hard time wrapping my head around how to efficiently organize scraping.\n",
    "\n",
    "Chat wrote a good function based on the functions that I wrote, but it is confusing and i'd like to understand it better, so I'm goign to start by going through those functions and trying to rewrite them in a way that makes sense to me.\n",
    "\n",
    "The goal here is to have a script that will pull from VENUES and scrape and then validate each of the artists performing at the venues, and then populate the ARTIST_EVENTS table.\n",
    "\n",
    "Ok so thats 3 different tasks, lets break them down.\n",
    "\n",
    "1. scrape the venues \n",
    "\n",
    "We have a few choices to make with the architeture. Ideally, we would be able to use something just like a scraping_params dict  \n",
    "       \"scraping_config\": {\n",
    "            \"base_url\": \"https://rickshawstop.com/?list1page=1\",\n",
    "            \"pagination\": {\n",
    "                \"enabled\": True,\n",
    "                \"pages\": 2,\n",
    "                \"url_pattern\": \"https://rickshawstop.com/?list1page={page}\"\n",
    "            },\n",
    "            \"selectors\": {\n",
    "                \"event_container\": \"div.event-info-block\",\n",
    "                \"artist\": \"p.fs-12.headliners\",\n",
    "                \"date\": \"p.fs-18.bold.mt-1r.date\",\n",
    "                \"genre\": None,\n",
    "                \"cancellation_indicator\": None\n",
    "            },\n",
    "            \"date_format\": \"%a %b %d\",\n",
    "            \"filters\": {\n",
    "                \"exclude_genres\": [],\n",
    "                \"check_cancelled\": False\n",
    "            }}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['venue_id', 'name', 'address', 'city', 'url', 'scraping_config', 'is_active', 'created_at', 'updated_at', 'validation_config']\n",
      "Ace of Spades\n",
      "Avogardro's Number\n",
      "Goldfield Trading Post\n",
      "Neck of the Woods\n",
      "Rickshaw Stop\n",
      "The Aggie Theatre\n",
      "The Armory\n",
      "The Chapel\n",
      "The Great American Music Hall\n",
      "The Independent\n",
      "The Mishawaka \n",
      "The Warfield\n",
      "Washington's\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(os.getenv('DATABASE_URL_UNPOOLED'))\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Get all active venues\n",
    "cur.execute(\"\"\"\n",
    "    SELECT * \n",
    "    FROM venues \n",
    "    WHERE is_active = TRUE\n",
    "    ORDER BY name;\n",
    "\"\"\")\n",
    "\n",
    "column_names = [desc[0] for desc in cur.description]\n",
    "print(\"Columns:\", column_names)\n",
    "\n",
    "# Get results\n",
    "res = cur.fetchall()\n",
    "venues = [dict(zip(column_names, v)) for v in res]\n",
    "for venue in venues:\n",
    "    print(venue['name'])\n",
    "# ret = dict(zip(column_names, venues[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_venue_html(soup, venue_id, scraping_config):\n",
    "    \"\"\"\n",
    "    Scraper for venues using HTML/CSS selectors\n",
    "    Returns list of events\n",
    "    \"\"\"\n",
    "    selectors = scraping_config['selectors']\n",
    "    date_format = scraping_config['date_format']\n",
    "    event_containers = soup.select(selectors['event_container'])\n",
    "    \n",
    "    events = []\n",
    "    \n",
    "    for container in event_containers:\n",
    "        try:\n",
    "            # Extract artists\n",
    "            artist_elem = container.select_one(selectors['artist'])\n",
    "            artist = artist_elem.text.strip() if artist_elem else None\n",
    "            \n",
    "            # Extract date\n",
    "            date_elem = container.select_one(selectors['date'])\n",
    "            date_text = date_elem.text.strip() if date_elem else None\n",
    "            parsed_date = parse_date(date_text, date_format) if date_text else None\n",
    "            \n",
    "            # Extract genre (if configured)\n",
    "            genre = None\n",
    "            if selectors.get('genre'):\n",
    "                genre_elem = container.select_one(selectors['genre'])\n",
    "                genre = genre_elem.text.strip() if genre_elem else None\n",
    "            \n",
    "            # Check if cancelled (if configured)\n",
    "            is_cancelled = False\n",
    "            if selectors.get('cancellation_indicator'):\n",
    "                cancel_elem = container.select_one(selectors['cancellation_indicator'])\n",
    "                if cancel_elem:\n",
    "                    cancelled_text = scraping_config.get('filters', {}).get('cancelled_text', 'Cancelled')\n",
    "                    is_cancelled = cancel_elem.text.strip() == cancelled_text\n",
    "            \n",
    "            # Only add if we got at minimum an artist and date\n",
    "            if artist and date_text:\n",
    "                events.append({\n",
    "                    'venue_id': venue_id,\n",
    "                    'raw_event_name': artist,\n",
    "                    'raw_date_text': date_text,\n",
    "                    'genres': genre,\n",
    "                    'is_cancelled': is_cancelled,\n",
    "                    'parsed_date': parsed_date\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Error parsing event: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_venue_json_ld(soup, venue_id, scraping_config):\n",
    "    \"\"\"\n",
    "    Scraper for venues using JSON-LD structured data\n",
    "    Returns list of events\n",
    "    \"\"\"\n",
    "    json_keys = scraping_config.get('json_keys')\n",
    "    if not json_keys:\n",
    "        print(f\"  ‚ùå Missing json_keys in config\")\n",
    "        return []\n",
    "    \n",
    "    # Find all JSON-LD script tags\n",
    "    script_tags = soup.find_all('script', type='application/ld+json')\n",
    "    events = []\n",
    "    \n",
    "    for script_tag in script_tags:\n",
    "        try:\n",
    "            # Clean control characters before parsing\n",
    "            json_text = script_tag.string\n",
    "            if json_text:\n",
    "                json_text = json_text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "                event_data = json.loads(json_text)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Skip if it's not an Event schema\n",
    "            if event_data.get('@type') != 'Event':\n",
    "                continue\n",
    "            \n",
    "            # Extract artist\n",
    "            artist = get_nested_value(event_data, json_keys.get('artist', 'performer'))\n",
    "            artist = html.unescape(str(artist)).strip() if artist else None\n",
    "            \n",
    "            # Extract date\n",
    "            date_string = get_nested_value(event_data, json_keys.get('date', 'startDate'))\n",
    "            \n",
    "            # Parse date based on format\n",
    "            parsed_date = None\n",
    "            date_text = None\n",
    "            if date_string:\n",
    "                try:\n",
    "                    date_format = scraping_config.get('date_format', 'iso')\n",
    "                    if date_format == 'iso':\n",
    "                        # Handle various ISO formats\n",
    "                        parsed_date = datetime.fromisoformat(date_string.replace('+00:00', '').replace('Z', ''))\n",
    "                        date_text = parsed_date.strftime('%Y-%m-%d')\n",
    "                    else:\n",
    "                        parsed_date = datetime.strptime(date_string, date_format)\n",
    "                        date_text = parsed_date.strftime('%Y-%m-%d')\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è Error parsing date '{date_string}': {e}\")\n",
    "                    date_text = date_string  # Fallback to raw string\n",
    "            \n",
    "            # Only add if we got at minimum an artist and date\n",
    "            if artist and date_text:\n",
    "                events.append({\n",
    "                    'venue_id': venue_id,\n",
    "                    'raw_event_name': artist,\n",
    "                    'raw_date_text': date_text,\n",
    "                    'genres': None,\n",
    "                    'is_cancelled': False,\n",
    "                    'parsed_date': parsed_date\n",
    "                })\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"  ‚ö†Ô∏è Skipping malformed JSON-LD script\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Error extracting event data: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return events\n",
    "\n",
    "def get_nested_value(data, key_path):\n",
    "    \"\"\"\n",
    "    Get value from nested dict using dot notation\n",
    "    e.g., 'location.name' returns data['location']['name']\n",
    "    \"\"\"\n",
    "    if not key_path:\n",
    "        return None\n",
    "        \n",
    "    keys = key_path.split('.')\n",
    "    value = data\n",
    "    \n",
    "    for key in keys:\n",
    "        if isinstance(value, dict):\n",
    "            value = value.get(key)\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "        if value is None:\n",
    "            return None\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ace of Spades\n",
      "added  36\n",
      "Avogardro's Number\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Thursday October 23rd 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Thursday October 23rd 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Friday October 24th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Friday October 24th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Saturday October 25th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Sunday October 26th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Sunday October 26th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Monday October 27th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Tuesday October 28th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Thursday October 30th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Friday October 31st 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Saturday November 1st 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Thursday November 6th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Friday November 7th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Saturday November 8th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Monday November 10th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Friday November 14th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Saturday November 15th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Friday November 21st 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Saturday November 22nd 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Saturday November 29th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Sunday January 18th 2025' does not match format '%A %B %d %Y'\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Saturday January 31st 2025' does not match format '%A %B %d %Y'\n",
      "added  0\n",
      "Goldfield Trading Post\n",
      "added  20\n",
      "Neck of the Woods\n",
      "added  36\n",
      "Rickshaw Stop\n",
      "  ‚Üí Getting page 1: https://rickshawstop.com/?list1page=1\n",
      "added  15\n",
      "  ‚Üí Getting page 2: https://rickshawstop.com/?list1page=2\n",
      "added  15\n",
      "  ‚Üí Getting page 3: https://rickshawstop.com/?list1page=3\n",
      "added  15\n",
      "  ‚Üí Getting page 4: https://rickshawstop.com/?list1page=4\n",
      "added  15\n",
      "  ‚Üí Getting page 5: https://rickshawstop.com/?list1page=5\n",
      "added  5\n",
      "added  5\n",
      "The Aggie Theatre\n",
      "added  43\n",
      "The Armory\n",
      "added  9\n",
      "The Chapel\n",
      "  ‚Üí Getting page 1: https://thechapelsf.com/music/?list1page=1\n",
      "added  13\n",
      "  ‚Üí Getting page 2: https://thechapelsf.com/music/?list1page=2\n",
      "added  14\n",
      "  ‚Üí Getting page 3: https://thechapelsf.com/music/?list1page=3\n",
      "added  13\n",
      "  ‚Üí Getting page 4: https://thechapelsf.com/music/?list1page=4\n",
      "added  14\n",
      "  ‚Üí Getting page 5: https://thechapelsf.com/music/?list1page=5\n",
      "added  14\n",
      "added  14\n",
      "The Great American Music Hall\n",
      "added  12\n",
      "The Independent\n",
      "added  73\n",
      "The Mishawaka \n",
      "  ‚ö†Ô∏è Error parsing event: time data 'Sat, June 20, 2026' does not match format '%a, %b %d, %Y'\n",
      "added  15\n",
      "The Warfield\n",
      "  ‚ö†Ô∏è Error parsing event: time data 'TBD' does not match format '%a, %b %d, %Y'\n",
      "added  30\n",
      "Washington's\n",
      "added  9\n"
     ]
    }
   ],
   "source": [
    "raw_events =[]\n",
    "driver = start_selenium()\n",
    "for target_venue in venues:\n",
    "    scraping_config = target_venue.get('scraping_config', {})\n",
    "    pagination = scraping_config.get('pagination', {})\n",
    "    selectors = scraping_config.get('selectors', {})\n",
    "    id = target_venue.get('venue_id')\n",
    "    print(target_venue.get('name'))\n",
    "    events_list=[]\n",
    "\n",
    "    soups = []\n",
    "\n",
    "    if pagination.get('enabled'):\n",
    "        url_pattern = pagination.get('url_pattern')\n",
    "        if pagination.get('enabled'): # bool\n",
    "            pages = pagination.get('pages', 1)\n",
    "            url_pattern = pagination.get('url_pattern')\n",
    "            for i in range(1, 6):\n",
    "                page_url = url_pattern.format(page=i)\n",
    "                print(f\"  ‚Üí Getting page {i}: {page_url}\")\n",
    "                try:\n",
    "                    driver.get(page_url)\n",
    "                    time.sleep(1)\n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    events = scrape_venue_html(soup, 9, target_venue['scraping_config'])\n",
    "                    raw_events.extend(events)\n",
    "                    print('added ', len(events))\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è  Timeout/error loading page {i}: {e}\")\n",
    "                    break\n",
    "\n",
    "    else:\n",
    "        driver.get(scraping_config.get('base_url'))\n",
    "        time.sleep(1)\n",
    "        method = scraping_config.get('scraping_method', 'html')\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        if method == 'html':\n",
    "            events = scrape_venue_html(soup, id, scraping_config)\n",
    "            raw_events.extend(events)\n",
    "        elif method == 'json-ld':\n",
    "            events = scrape_venue_json_ld(soup, id, scraping_config)\n",
    "            raw_events.extend(events)\n",
    "    print('added ', len(events))\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_id</th>\n",
       "      <th>raw_event_name</th>\n",
       "      <th>raw_date_text</th>\n",
       "      <th>genres</th>\n",
       "      <th>is_cancelled</th>\n",
       "      <th>parsed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Kublai Khan TX</td>\n",
       "      <td>Thu Oct 23, 2025</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>DJ Pauly D</td>\n",
       "      <td>Fri Oct 24, 2025</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Yung Gravy: Voluptuous Voyage Tour</td>\n",
       "      <td>Sat Oct 25, 2025</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>The Buttertones</td>\n",
       "      <td>Sun Oct 26, 2025</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Spafford</td>\n",
       "      <td>Wed Oct 29, 2025</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>14</td>\n",
       "      <td>105.5 The Colorado Sound Welcomes</td>\n",
       "      <td>Saturday, November 1 @ 7:00 pm</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>14</td>\n",
       "      <td>Washington's and Live Nation present</td>\n",
       "      <td>Friday, November 14 @ 7:30 pm</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>14</td>\n",
       "      <td>105.5 The Colorado Sound Welcomes</td>\n",
       "      <td>Saturday, November 15 @ 7:00 pm</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>14</td>\n",
       "      <td>105.5 The Colorado Sound Welcomes</td>\n",
       "      <td>Saturday, November 22 @ 7:00 pm</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>14</td>\n",
       "      <td>105.5 The Colorado Sound Welcomes</td>\n",
       "      <td>Friday, November 28 @ 8:00 pm</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     venue_id                        raw_event_name  \\\n",
       "0          29                        Kublai Khan TX   \n",
       "1          29                            DJ Pauly D   \n",
       "2          29    Yung Gravy: Voluptuous Voyage Tour   \n",
       "3          29                       The Buttertones   \n",
       "4          29                              Spafford   \n",
       "..        ...                                   ...   \n",
       "411        14     105.5 The Colorado Sound Welcomes   \n",
       "412        14  Washington's and Live Nation present   \n",
       "413        14     105.5 The Colorado Sound Welcomes   \n",
       "414        14     105.5 The Colorado Sound Welcomes   \n",
       "415        14     105.5 The Colorado Sound Welcomes   \n",
       "\n",
       "                       raw_date_text genres  is_cancelled parsed_date  \n",
       "0                   Thu Oct 23, 2025   None         False  2025-10-23  \n",
       "1                   Fri Oct 24, 2025   None         False  2025-10-24  \n",
       "2                   Sat Oct 25, 2025   None         False  2025-10-25  \n",
       "3                   Sun Oct 26, 2025   None         False  2025-10-26  \n",
       "4                   Wed Oct 29, 2025   None         False  2025-10-29  \n",
       "..                               ...    ...           ...         ...  \n",
       "411   Saturday, November 1 @ 7:00 pm   None         False  2025-11-01  \n",
       "412    Friday, November 14 @ 7:30 pm   None         False  2025-11-14  \n",
       "413  Saturday, November 15 @ 7:00 pm   None         False  2025-11-15  \n",
       "414  Saturday, November 22 @ 7:00 pm   None         False  2025-11-22  \n",
       "415    Friday, November 28 @ 8:00 pm   None         False  2025-11-28  \n",
       "\n",
       "[352 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(raw_events)\n",
    "raw_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv('raw_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (416294713.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break\n",
    "import json\n",
    "import psycopg2\n",
    "import os\n",
    "# scrape venue\n",
    "# pagination\n",
    "venues = [\n",
    "    {\"venue_id\": \"3\", \n",
    "        \"name\": \"The Warfield\",\n",
    "        \"address\": \"982 Market Street\",\n",
    "        \"city\": \"San Francisco\",\n",
    "        \"scraping_config\": {\n",
    "            \"base_url\": \"https://www.thewarfieldtheatre.com/events\",\n",
    "            \"pagination\": {\n",
    "                \"enabled\": False,\n",
    "            },\n",
    "            \"selectors\": {\n",
    "                \"event_container\": \"div.entry.warfield.clearfix\",\n",
    "                \"artist\": \"h3.carousel_item_title_small\",\n",
    "                \"support\": 'h4.animated',\n",
    "                \"date\": \"span.date\",\n",
    "                \"genre\": None,\n",
    "                \"cancellation_indicator\": None\n",
    "            },\n",
    "            \"date_format\": \"%a, %b %d, %Y\",\n",
    "            }},\n",
    "\n",
    "                {\n",
    "                    \"venue_id\": \"2\", \n",
    "        \"name\": \"The Great American Music Hall\",\n",
    "        \"address\": \"859 O‚ÄôFarrell St.\",\n",
    "        \"city\": \"San Francisco\",\n",
    "        \"scraping_config\": {\n",
    "            \"base_url\": \"https://gamh.com/\",\n",
    "            \"pagination\": {\n",
    "                \"enabled\": False,\n",
    "            },\n",
    "            \"selectors\": {\n",
    "                \"event_container\": \"div.seetickets-list-event-content-container.position-relative\",\n",
    "                \"artist\": \"p.fs-12.headliners\",\n",
    "                \"support\": 'p.fs-12.supporting-talent',\n",
    "                \"date\": \"p.fs-18.bold.mt-1r.event-date\",\n",
    "                \"genre\": None,\n",
    "                \"cancellation_indicator\": None\n",
    "            },\n",
    "            \"date_format\": \"%a %b %d\",\n",
    "            }},\n",
    "\n",
    "                {\n",
    "                    \"venue_id\": \"4\", \n",
    "        \"name\": \"Neck of the Woods\",\n",
    "        \"address\": \"406 Clement St\",\n",
    "        \"city\": \"San Francisco\",\n",
    "        \"scraping_config\": {\n",
    "            \"base_url\": \"https://www.neckofthewoodssf.com/page/2/\",\n",
    "            \"selectors\": {\n",
    "                \"event_container\": \"div.tw-section\",\n",
    "                \"artist\": \"div.tw-name\",\n",
    "                \"support\": None,\n",
    "                \"date\": \"div.tw-event-datetime \",\n",
    "                \"genre\": None,\n",
    "                \"cancellation_indicator\": None\n",
    "            },\n",
    "            \"date_format\": \"%a, %b %d\",\n",
    "            }},\n",
    "\n",
    "{\"venue_id\": \"1\", \n",
    "    \"name\": \"The Aggie Theatre\",\n",
    "    \"address\": \"204 S College Avenue\",\n",
    "    \"city\": \"Fort Collins\",\n",
    "    \"scraping_config\": {\n",
    "        \"scraping_method\": \"json-ld\",  # or \"html\" for regular scraping\n",
    "        \"base_url\": \"https://www.fortcollinsmusichall.com/events/\",\n",
    "        \"json_keys\": {\n",
    "            \"artist\": \"performer\",\n",
    "            \"date\": \"startDate\",\n",
    "            \"venue\": \"location.name\",\n",
    "            \"url\": \"url\"\n",
    "        },\n",
    "        \"date_format\": \"iso\"\n",
    "    }\n",
    "}, \n",
    "{\"venue_id\": \"5\", \n",
    "    \"name\": \"Washington's\",\n",
    "    \"address\": \"132 Laporte Ave\",\n",
    "    \"city\": \"Fort Collins\",\n",
    "    \"scraping_config\": {\n",
    "        \"scraping_method\": \"html\",\n",
    "        \"base_url\": \"https://bohemianlivemusic.org/our-venues/washingtons/\",\n",
    "        \"selectors\": {\n",
    "            \"event_container\": \"div.elementor-element.elementor-element-18ac28d.e-flex.e-con-boxed.e-con.e-child\",\n",
    "            \"artist\": \"div.elementor-widget-container\",\n",
    "            \"support\": None,\n",
    "            \"date\": \"span.elementor-icon-list-text.elementor-post-info__item.elementor-post-info__item--type-custom\",\n",
    "            \"genre\": None,\n",
    "            \"cancellation_indicator\": None\n",
    "        },\n",
    "        \"date_format\": \"%A, %B %d @ %I:%M %p\"\n",
    "    }\n",
    "},\n",
    "{\"venue_id\": \"6\", \n",
    "    \"name\": \"The Mishawaka \",\n",
    "    \"address\": \"13714 Poudre Canyon Highway\",\n",
    "    \"city\": \"Fort Collins\",\n",
    "    \"scraping_config\": {\n",
    "        \"scraping_method\": \"html\",\n",
    "        \"base_url\": \"https://www.themishawaka.com/events/?view=list\",\n",
    "        \"selectors\": {\n",
    "            \"event_container\": \"div.col-12.eventWrapper.rhpSingleEvent.py-4.px-0\",\n",
    "            \"artist\": \"#eventTitle h2\",\n",
    "            \"support\": None,\n",
    "            \"date\": \"#eventDate\",\n",
    "            \"genre\": None,\n",
    "            \"cancellation_indicator\": None\n",
    "        },\n",
    "        \"date_format\": \"%a, %b %d, %Y\"\n",
    "    }\n",
    "}\n",
    "]\n",
    "# Connect to database\n",
    "conn = psycopg2.connect(os.getenv('DATABASE_URL_UNPOOLED'))\n",
    "cur = conn.cursor()\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO venues (name, address, city, url, scraping_config)\n",
    "VALUES (%s, %s, %s, %s, %s)\n",
    "ON CONFLICT (url) DO UPDATE SET\n",
    "    name = EXCLUDED.name,\n",
    "    address = EXCLUDED.address,\n",
    "    city = EXCLUDED.city,\n",
    "    scraping_config = EXCLUDED.scraping_config,\n",
    "    updated_at = CURRENT_TIMESTAMP\n",
    "RETURNING venue_id, name;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    for venue in venues:\n",
    "        cur.execute(insert_query, (\n",
    "            venue[\"name\"],\n",
    "            venue[\"address\"],\n",
    "            venue[\"city\"],\n",
    "            venue[\"scraping_config\"][\"base_url\"],  # Use base_url as url\n",
    "            json.dumps(venue[\"scraping_config\"])\n",
    "        ))\n",
    "        venue_id, name = cur.fetchone()\n",
    "        print(f\"‚úÖ Inserted/Updated: {name} (ID: {venue_id})\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"\\nüéâ Successfully processed {len(venues)} venues!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"‚ùå Error inserting venues: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playlist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
